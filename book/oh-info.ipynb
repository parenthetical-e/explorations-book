{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# The Oh My Information - Lab\n",
    "\n",
    "In this assignment we take on, and return to, _taxic explorations_. We revisit the sniff world (aka _ScentGrid_) now with a new twist. We look at what happens when sense information is not just noisy, but suddenly missing altogether. A concrete case of this is turbulent flows. \n",
    "\n",
    "We'll be working with a crude approximation of such turbulent flows. \n",
    "\n",
    "Our environment this tims just deletes scent information from the grid, with a probability $(1- p_{scent})$. The noisy background is of course unaffected by this deletion.\n",
    "\n",
    "The presence of this dual uncertainty makes decisions--of the kind common to decision theory--a necessity. Even more so than in the _Air Cognition Lab_. So, we'll be using accumulator models again. \n",
    "\n",
    "The decisions to be made are: \n",
    "\n",
    "- Q1: Is there a scent at all?\n",
    "- Q2: Is the gradient of the scent increasing or decreasing? \n",
    "\n",
    "Our target metrics are the number of deaths (_num. death_) and _total reward_. Any experimental trial which does not lead to finding at least a single target (aka reward) means the exploring agent dies. It's a harsh noisy world we live in, after all. \n",
    "\n",
    "## E Coli, again?\n",
    "_Background_: Recall our basic model of E. Coli exploration is as simple as can be. \n",
    "\n",
    "- When the gradient is positive, meaning you are going \"up\" the gradient, the probability of turning is set to _p pos_. \n",
    "- When the gradient is negative, the turning probability is set to _p neg_. (See code below, for an example). \n",
    "- If the agent \"decides\" to turn, the direction it takes is uniform random.\n",
    "- The length of travel before the next turn decision is sampled from an exponential distribution just like the _DiffusionDiscrete_\n",
    "\n",
    "## Our agents, this time\n",
    "We will study three agents. One who does _chemotaxis_. One who does a kind of _infotaxis_. One that does random search (aka Diffusion). For fun, let's call this one a _randotaxis_ agent. (No one really calls them this.) This last rando-agent is really a control. A reference point.\n",
    "\n",
    "In a sense the _chemotaxis_ agent only tries to answer question Q2 (above). While _infotaxis_ only tries to answer Q1. They are extreme strategies, in other words. The bigger question we will ask, in a very limited setting, is which extreme method is better _generally_? \n",
    "\n",
    "We will not address the question of combining them, into a less extreme and perhaps more reliable alternative...\n",
    "\n",
    "## Costly cognition\n",
    "Both _chemo-_ and _infotaxis_ agents will use a DDM-style accumulator to try and make better decisions about the direction of the gradient. These decisions are of course statistical in nature. (We won't be tuning the accumulator parameters in this lab. Assume the parameters I give you, for the DDM, are \"good enough\".)\n",
    "\n",
    "For the _randotaxis_ agent number of steps means the number of steps or actions the agent takes. \n",
    "\n",
    "As in the _Air Quotes Lab_ we will assume that the steps are in a sense conserved. For the other two (accumulator) agents a step can mean two things. For accumulator agents a step can be spent sampling/weighing noisy scent evidence in the same location, or it can be spent moving to a new location.\n",
    "\n",
    "## What's scent look like (a definition of _chemotaxis_)?\n",
    "Our _chemotaxis_ agent (_AccumulatorGradientGrid_) tries to directly estimate the gradient $\\nabla$ in scent by comparing the level of scent at the last grid position it occupied to the current scent level ($o$). By last grid position here we mean the last grid position when it moved last. \n",
    "\n",
    "$$\\nabla \\approx o_t - o_{t-1}$$\n",
    "\n",
    "Because an accumulator is present, our chemo- sequentially tries to estimate this gradient by sampling the new current location, until the threshold is met.\n",
    "\n",
    " Chemo-accumulators have what we can think of as two cognitive or behavioral steps:\n",
    "\n",
    "1. Use an accumulator to (stabely) estimate the chemo gradient\n",
    "2. Use the gradient to make turning decisions\n",
    "\n",
    "## More information (a definition of _infotaxis_)?\n",
    "Compared to chemo- definition the definition of infotaxis is a little more involved. It has what we can think of as five cognitive or behavioral steps:\n",
    "\n",
    "1. Use an accumulator to (stabely) estimate if there is a scent or not. AKA hits and misses.\n",
    "2. Build a probability model of hits/misses (at every point)\n",
    "3. Measure information gained when probability model changes \n",
    "4. Measure the gradient of information gains\n",
    "5. Use the gradient to make turning decisions\n",
    "\n",
    "_Note_: Even though the info-accumulator is more complex, it can take advantage of missing scent information to drive its behavior. It can also use positive scent hits, of course, too.\n",
    "\n",
    "## Our TED talk moment\n",
    "The big question for the week is this - is it ever better to follow the scent gradient instead of following its information?\n",
    "\n",
    "## Install and import needed modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install explorationlib?\n",
    "!pip install --upgrade git+https://github.com/parenthetical-e/explorationlib\n",
    "!pip install --upgrade git+https://github.com/MattChanTK/gym-maze.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "import explorationlib\n",
    "from explorationlib.local_gym import ScentGrid\n",
    "\n",
    "from explorationlib.agent import DiffusionGrid\n",
    "from explorationlib.agent import AccumulatorGradientGrid\n",
    "from explorationlib.agent import AccumulatorInfoGrid\n",
    "\n",
    "from explorationlib.run import experiment\n",
    "from explorationlib.util import select_exp\n",
    "from explorationlib.util import load\n",
    "from explorationlib.util import save\n",
    "\n",
    "from explorationlib.local_gym import uniform_targets\n",
    "from explorationlib.local_gym import constant_values\n",
    "from explorationlib.local_gym import ScentGrid\n",
    "from explorationlib.local_gym import create_grid_scent\n",
    "from explorationlib.local_gym import add_noise\n",
    "from explorationlib.local_gym import create_grid_scent_patches\n",
    "\n",
    "from explorationlib.plot import plot_position2d\n",
    "from explorationlib.plot import plot_length_hist\n",
    "from explorationlib.plot import plot_length\n",
    "from explorationlib.plot import plot_targets2d\n",
    "from explorationlib.plot import plot_scent_grid\n",
    "from explorationlib.plot import plot_targets2d\n",
    "\n",
    "from explorationlib.score import total_reward\n",
    "from explorationlib.score import num_death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty plots\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.greedy=True\n",
    "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"font.size\"] = \"16\"\n",
    "\n",
    "# Dev\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "## Section 1 -  Intelligent costs, for fun\n",
    "### Random search versus Cognition, when information is often missing and noisy\n",
    "\n",
    "To build some intuition, let's plot the \"scent\" emitted by a single target. That same scent corrupts by 1/2 a standard deviation of noise. That same signal, with all but 10 percent of it deleted. That same signal corrupted by noise _and_ all but 10 percent of it deleted."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Full scent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 1\n",
    "\n",
    "coord, scent = create_grid_scent_patches(\n",
    "        target_boundary, p=1.0, amplitude=amplitude, sigma=2)\n",
    "        \n",
    "plt.imshow(scent, interpolation=None)"
   ]
  },
  {
   "source": [
    "### Noisy scent\n",
    "A single examaple."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 1\n",
    "noise_sigma = 0.5\n",
    "\n",
    "coord, scent = create_grid_scent_patches(target_boundary, p=1.0, amplitude=amplitude, sigma=2)\n",
    "scent = add_noise(scent, noise_sigma)\n",
    "\n",
    "plt.imshow(scent, interpolation=None)"
   ]
  },
  {
   "source": [
    "Average 100 noisy scents to prove the original pure scent is still in there."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 1\n",
    "noise_sigma = 0.5\n",
    "num_samples = 100\n",
    "\n",
    "scents = []\n",
    "for _ in range(num_samples):\n",
    "    coord, scent = create_grid_scent_patches(target_boundary, p=1.0, amplitude=1, sigma=2)\n",
    "    scent = add_noise(scent, noise_sigma)\n",
    "    scents.append(deepcopy(scent))\n",
    "\n",
    "scent = np.sum(scents, axis=0)\n",
    "\n",
    "plt.imshow(scent, interpolation=None)"
   ]
  },
  {
   "source": [
    "### Missing scent\n",
    "A single example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 1000\n",
    "p_scent = 0.1\n",
    "\n",
    "coord, scent = create_grid_scent_patches(target_boundary, p=p_scent, amplitude=amplitude, sigma=2)\n",
    "\n",
    "plt.imshow(scent, interpolation=None)"
   ]
  },
  {
   "source": [
    "Average 100 of partially misssing scents to prove the original pure scent is still in there."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 1\n",
    "p_scent = 0.1\n",
    "num_samples = 100\n",
    "\n",
    "scents = []\n",
    "for _ in range(num_samples):\n",
    "    coord, scent = create_grid_scent_patches(target_boundary, p=p_scent, amplitude=1, sigma=2)\n",
    "    scents.append(deepcopy(scent))\n",
    "\n",
    "scent = np.sum(scents, axis=0)\n",
    "\n",
    "plt.imshow(scent, interpolation=None)"
   ]
  },
  {
   "source": [
    "### Noisy and missing scent\n",
    "A single examaple"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 1\n",
    "noise_sigma = 0.5\n",
    "p_scent = 0.1\n",
    ";\n",
    "coord, scent = create_grid_scent_patches(target_boundary, p=p_scent, amplitude=amplitude, sigma=2)\n",
    "scent = add_noise(scent, noise_sigma)\n",
    "\n",
    "plt.imshow(scent, interpolation=None)"
   ]
  },
  {
   "source": [
    "Average 100 of partially misssing _and_ noisy scents to prove the original pure scent is still in there."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 1\n",
    "noise_sigma = 0.5\n",
    "p_scent = 0.1\n",
    "num_samples = 100\n",
    "\n",
    "scents = []\n",
    "for _ in range(num_samples):\n",
    "    coord, scent = create_grid_scent_patches(target_boundary, p=p_scent, amplitude=1, sigma=2)\n",
    "    scent = add_noise(scent, noise_sigma)\n",
    "    scents.append(deepcopy(scent))\n",
    "    \n",
    "scent = np.sum(scents, axis=0)\n",
    "\n",
    "plt.imshow(scent, interpolation=None)"
   ]
  },
  {
   "source": [
    "#### Question 1.1\n",
    "When scent is both noisy, and missing, the cost (in steps) of using cognition (aka accumulator-based evidential decision making) may not be worth it? \n",
    "\n",
    "If we define \"worth it\" to be both total reward, and num deaths, what do you think? Without a positive cognition step multiplier factor (as in the Air Cog Lab), will either chemo- or info-taxis agents outperform random search?\n",
    "\n",
    "_Hint_: this is not a blind guess. If you change _num. samples_ in the plots above, to say between 2-10, you will get an estimate of how the accumulator may \"see\" the problem. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain your reasoning. "
   ]
  },
  {
   "source": [
    "#### Question 1.2\n",
    "In Q1.1 I said\n",
    "\n",
    ">  If you change _num. samples_ in the plots above, to say between 2-10, you will get an estimate of how the accumulator may \"see\" the problem. \n",
    "\n",
    "Can you explain in your own words why this assertion was correct? (Or if you think it was not correct, explain why)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain your reasoning. "
   ]
  },
  {
   "source": [
    "Let's find out how helpful or not cognition is when scents are noisy and missing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise and delete\n",
    "p_scent = 0.1\n",
    "noise_sigma = 0.5\n",
    "\n",
    "# Shared \n",
    "num_experiments = 100\n",
    "num_steps = 200\n",
    "seed_value = 5838\n",
    "\n",
    "# ! (leave alone)\n",
    "detection_radius = 1\n",
    "cog_mult = 1\n",
    "max_steps = 1\n",
    "min_length = 1\n",
    "num_targets = 10\n",
    "target_boundary = (10, 10)\n",
    "\n",
    "# Targets\n",
    "prng = np.random.RandomState(seed_value)\n",
    "targets = uniform_targets(num_targets, target_boundary, prng=prng)\n",
    "values = constant_values(targets, 1)\n",
    "\n",
    "# Scents\n",
    "scents = []\n",
    "for _ in range(len(targets)):\n",
    "    coord, scent = create_grid_scent_patches(\n",
    "        target_boundary, p=1.0, amplitude=1, sigma=2)\n",
    "    scents.append(scent)\n",
    "\n",
    "# Env\n",
    "env = ScentGrid(mode=None)\n",
    "env.seed(seed_value)\n",
    "env.add_scents(targets, values, coord, scents, noise_sigma=noise_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "diff = DiffusionGrid(min_length=min_length, scale=1)\n",
    "diff.seed(seed_value)\n",
    "\n",
    "chemo = AccumulatorGradientGrid(\n",
    "    min_length=min_length, \n",
    "    max_steps=max_steps, \n",
    "    drift_rate=1, \n",
    "    threshold=3,\n",
    "    accumulate_sigma=1\n",
    ")\n",
    "chemo.seed(seed_value)\n",
    "\n",
    "info = AccumulatorInfoGrid(\n",
    "    min_length=min_length, \n",
    "    max_steps=max_steps, \n",
    "    drift_rate=1, \n",
    "    threshold=3,\n",
    "    accumulate_sigma=1\n",
    ")\n",
    "info.seed(seed_value)\n",
    "\n",
    "# !\n",
    "rand_exp = experiment(\n",
    "    f\"rand\",\n",
    "    diff,\n",
    "    env,\n",
    "    num_steps=num_steps,\n",
    "    num_experiments=num_experiments,\n",
    "    dump=False,\n",
    "    split_state=True,\n",
    "    seed=seed_value\n",
    ")\n",
    "chemo_exp = experiment(\n",
    "    f\"chemo\",\n",
    "    chemo,\n",
    "    env,\n",
    "    num_steps=num_steps * cog_mult,\n",
    "    num_experiments=num_experiments,\n",
    "    dump=False,\n",
    "    split_state=True,\n",
    "    seed=seed_value\n",
    ")\n",
    "info_exp = experiment(\n",
    "    f\"info\",\n",
    "    info,\n",
    "    env,\n",
    "    num_steps=num_steps * cog_mult,\n",
    "    num_experiments=num_experiments,\n",
    "    dump=False,\n",
    "    split_state=True,\n",
    "    seed=seed_value\n",
    ")"
   ]
  },
  {
   "source": [
    "### Behavior\n",
    "A single example "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary = (20, 20)\n",
    "\n",
    "# -\n",
    "num_experiment = 0\n",
    "ax = None\n",
    "ax = plot_position2d(\n",
    "    select_exp(chemo_exp, num_experiment),\n",
    "    boundary=plot_boundary,\n",
    "    label=\"Chemo\",\n",
    "    color=\"blue\",\n",
    "    alpha=0.6,\n",
    "    ax=ax,\n",
    ")\n",
    "ax = plot_position2d(\n",
    "    select_exp(info_exp, num_experiment),\n",
    "    boundary=plot_boundary,\n",
    "    label=\"Info\",\n",
    "    color=\"green\",\n",
    "    alpha=0.6,\n",
    "    ax=ax,\n",
    ")\n",
    "ax = plot_position2d(\n",
    "    select_exp(rand_exp, num_experiment),\n",
    "    boundary=plot_boundary,\n",
    "    label=\"Rando\",\n",
    "    color=\"grey\",\n",
    "    alpha=0.8,\n",
    "    ax=ax,\n",
    ")\n",
    "ax = plot_targets2d(\n",
    "    env,\n",
    "    boundary=plot_boundary,\n",
    "    color=\"black\",\n",
    "    alpha=1,\n",
    "    label=\"Targets\",\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "source": [
    "### Total distance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "results = [chemo_exp, info_exp, rand_exp]\n",
    "names = [\"Chemo\", \"Info\", \"Rando\"]\n",
    "colors = [\"blue\", \"green\", \"grey\"]\n",
    "\n",
    "# Score by eff\n",
    "scores = []\n",
    "for name, res, color in zip(names, results, colors):\n",
    "    l = 0.0\n",
    "    for r in res:\n",
    "        l += r[\"agent_total_l\"][-1]\n",
    "    scores.append(l)   \n",
    "\n",
    "# Tabulate\n",
    "m, sd = [], []\n",
    "for (name, s, c) in zip(names, scores, colors):\n",
    "    m.append(np.mean(s))\n",
    "    sd.append(np.std(s))\n",
    "\n",
    "# Plot means\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Total distance\")\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "source": [
    "### Deaths"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "results = [chemo_exp, info_exp, rand_exp]\n",
    "names = [\"Chemo\", \"Info\", \"Rando\"]\n",
    "colors = [\"blue\", \"green\", \"grey\"]\n",
    "\n",
    "# Score by eff\n",
    "scores = []\n",
    "for name, res, color in zip(names, results, colors):\n",
    "    scores.append(num_death(res))   \n",
    "\n",
    "# Tabulate\n",
    "m, sd = [], []\n",
    "for (name, s, c) in zip(names, scores, colors):\n",
    "    m.append(np.mean(s))\n",
    "    sd.append(np.std(s))\n",
    "\n",
    "# Plot means\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Deaths\")\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "source": [
    "### Total reward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "results = [chemo_exp, info_exp, rand_exp]\n",
    "names = [\"Chemo\", \"Info\", \"Rando\"]\n",
    "colors = [\"blue\", \"green\", \"grey\"]\n",
    "\n",
    "# Score by eff\n",
    "scores = []\n",
    "for name, res, color in zip(names, results, colors):\n",
    "    r = total_reward(res)\n",
    "    scores.append(r)   \n",
    "\n",
    "# Tabulate\n",
    "m, sd = [], []\n",
    "for (name, s, c) in zip(names, scores, colors):\n",
    "    m.append(np.mean(s))\n",
    "    sd.append(np.std(s))\n",
    "\n",
    "# Plot means\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Total reward\")\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "\n",
    "# Dists\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "for (name, s, c) in zip(names, scores, colors):\n",
    "    plt.hist(s, label=name, color=c, alpha=0.5, bins=np.linspace(0, np.max(scores), 50))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    sns.despine()"
   ]
  },
  {
   "source": [
    "#### Question 1.3\n",
    "So, is cognition worth it in the example following Q1.2? Were you right?\n",
    "\n",
    "Base your answer on the number of deaths contrasted to the total reward. Both of which are plotted above."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain yourself."
   ]
  },
  {
   "source": [
    "#### Question 1.4\n",
    "Why were the number of deaths (...probably) so much higher for chemo- and info-taxis?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain yourself."
   ]
  },
  {
   "source": [
    "## Section 2 -  Missing and noisy scents\n",
    "\n",
    "Let's add a cog. mult. of 4. This will be enough to make evidential decisions \"worth it\". \n",
    "\n",
    "Having set our multiplier, let's compare chemo- and info-taxis in a setting which should favor info. We are not interested then _if_ info does better, but by how much."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_mult = 4"
   ]
  },
  {
   "source": [
    "#### Question 2.1\n",
    "When there are \"many\" targets (50), and when noise is \"high\" (2), and scent of \"often\" missing (0.1) how much better will info-taxis be than info? \n",
    "\n",
    "Express this as a factor. For example, \"I think info will be 2 x better\" or \"I think info will be 1 x better\" (aka the same).\n",
    "\n",
    "Before you jump to speculating, you might want to reread the opening section of this Lab, where I explain how info and chem gradients are estimated, and what goes into those estimates?\n",
    "\n",
    "Give a factor answer for both _total reward_ and _num. deaths_."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's find out"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise and delete\n",
    "p_scent = 0.1\n",
    "noise_sigma = 2\n",
    "\n",
    "# Shared \n",
    "num_experiments = 200\n",
    "num_steps = 200\n",
    "seed_value = 5838\n",
    "\n",
    "# ! (leave alone)\n",
    "detection_radius = 1\n",
    "max_steps = 1\n",
    "min_length = 1\n",
    "\n",
    "num_targets = 50\n",
    "target_boundary = (10, 10)\n",
    "\n",
    "# Targets\n",
    "prng = np.random.RandomState(seed_value)\n",
    "targets = uniform_targets(num_targets, target_boundary, prng=prng)\n",
    "values = constant_values(targets, 1)\n",
    "\n",
    "# Scents\n",
    "scents = []\n",
    "for _ in range(len(targets)):\n",
    "    coord, scent = create_grid_scent_patches(\n",
    "        target_boundary, p=p_scent, amplitude=1, sigma=2)\n",
    "    scents.append(scent)\n",
    "\n",
    "# Env\n",
    "env = ScentGrid(mode=None)\n",
    "env.seed(seed_value)\n",
    "env.add_scents(targets, values, coord, scents, noise_sigma=noise_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "diff = DiffusionGrid(min_length=min_length, scale=1)\n",
    "diff.seed(seed_value)\n",
    "\n",
    "chemo = AccumulatorGradientGrid(\n",
    "    min_length=min_length, \n",
    "    max_steps=max_steps, \n",
    "    drift_rate=1, \n",
    "    threshold=3,\n",
    "    accumulate_sigma=1\n",
    ")\n",
    "chemo.seed(seed_value)\n",
    "\n",
    "info = AccumulatorInfoGrid(\n",
    "    min_length=min_length, \n",
    "    max_steps=max_steps, \n",
    "    drift_rate=1, \n",
    "    threshold=3,\n",
    "    accumulate_sigma=1\n",
    ")\n",
    "info.seed(seed_value)\n",
    "\n",
    "# !\n",
    "rand_exp = experiment(\n",
    "    f\"rand\",\n",
    "    diff,\n",
    "    env,\n",
    "    num_steps=num_steps,\n",
    "    num_experiments=num_experiments,\n",
    "    dump=False,\n",
    "    split_state=True,\n",
    "    seed=seed_value\n",
    ")\n",
    "chemo_exp = experiment(\n",
    "    f\"chemo\",\n",
    "    chemo,\n",
    "    env,\n",
    "    num_steps=num_steps * cog_mult,\n",
    "    num_experiments=num_experiments,\n",
    "    dump=False,\n",
    "    split_state=True,\n",
    "    seed=seed_value\n",
    ")\n",
    "info_exp = experiment(\n",
    "    f\"info\",\n",
    "    info,\n",
    "    env,\n",
    "    num_steps=num_steps * cog_mult,\n",
    "    num_experiments=num_experiments,\n",
    "    dump=False,\n",
    "    split_state=True,\n",
    "    seed=seed_value\n",
    ")"
   ]
  },
  {
   "source": [
    "### Deaths"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "results = [chemo_exp, info_exp, rand_exp]\n",
    "names = [\"Chemo\", \"Info\", \"Rando\"]\n",
    "colors = [\"blue\", \"green\", \"grey\"]\n",
    "\n",
    "# Score by eff\n",
    "scores = []\n",
    "for name, res, color in zip(names, results, colors):\n",
    "    scores.append(num_death(res))   \n",
    "\n",
    "# Tabulate\n",
    "m, sd = [], []\n",
    "for (name, s, c) in zip(names, scores, colors):\n",
    "    m.append(np.mean(s))\n",
    "    sd.append(np.std(s))\n",
    "\n",
    "# Plot means\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Deaths\")\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "source": [
    "### Total reward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "results = [chemo_exp, info_exp, rand_exp]\n",
    "names = [\"Chemo\", \"Info\", \"Rando\"]\n",
    "colors = [\"blue\", \"green\", \"grey\"]\n",
    "\n",
    "# Score by eff\n",
    "scores = []\n",
    "for name, res, color in zip(names, results, colors):\n",
    "    r = total_reward(res)\n",
    "    scores.append(r)   \n",
    "\n",
    "# Tabulate\n",
    "m, sd = [], []\n",
    "for (name, s, c) in zip(names, scores, colors):\n",
    "    m.append(np.mean(s))\n",
    "    sd.append(np.std(s))\n",
    "\n",
    "# Plot means\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Total reward\")\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "\n",
    "# Dists\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "for (name, s, c) in zip(names, scores, colors):\n",
    "    plt.hist(s, label=name, color=c, alpha=0.5, bins=np.linspace(0, np.max(scores), 50))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "#### Question 2.2\n",
    "Was your answer to 2.1 correct? If it was not, explain what you think you got wrong. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain your old intuition and if it has changed your new one."
   ]
  },
  {
   "source": [
    "## Section 3 -  Strong, but a little noisy\n",
    "\n",
    "Let's add a cog. mult. of 4. This will be enough to make evidenctial decsions \"worth it\". "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_mult = 4"
   ]
  },
  {
   "source": [
    "### Question 3.1\n",
    "When there are \"many\" targets (50), and when noise is \"low\" 1.0), how much better will chemo-taxis be than info? \n",
    "\n",
    "Express this as a factor. For example, \"I think chemo will be 2 x better\" or \"I think chemo will be 1 x better\" (aka the same).\n",
    "\n",
    "Before you jump to speculating, you might want to reread the opening section of this Lab, where I explain how info and chem gradients are estimated, and what goes into those estimates?\n",
    "\n",
    "Give a factor answer for both _total reward_ and _num. deaths_."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain yourself (as best you can)."
   ]
  },
  {
   "source": [
    "Let's find out!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise and delete\n",
    "p_scent = 1.0\n",
    "noise_sigma = 1.0\n",
    "\n",
    "# Shared \n",
    "num_experiments = 100\n",
    "num_steps = 200\n",
    "seed_value = 5838\n",
    "\n",
    "# ! (leave alone)\n",
    "detection_radius = 1\n",
    "max_steps = 1\n",
    "min_length = 1\n",
    "num_targets = 50\n",
    "target_boundary = (10, 10)\n",
    "\n",
    "# Targets\n",
    "prng = np.random.RandomState(seed_value)\n",
    "targets = uniform_targets(num_targets, target_boundary, prng=prng)\n",
    "values = constant_values(targets, 1)\n",
    "\n",
    "# Scents\n",
    "scents = []\n",
    "for _ in range(len(targets)):\n",
    "    coord, scent = create_grid_scent_patches(\n",
    "        target_boundary, p=p_scent, amplitude=1, sigma=2)\n",
    "    scents.append(scent)\n",
    "\n",
    "# Env\n",
    "env = ScentGrid(mode=None)\n",
    "env.seed(seed_value)\n",
    "env.add_scents(targets, values, coord, scents, noise_sigma=noise_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "diff = DiffusionGrid(min_length=min_length, scale=1)\n",
    "diff.seed(seed_value)\n",
    "\n",
    "chemo = AccumulatorGradientGrid(\n",
    "    min_length=min_length, \n",
    "    max_steps=max_steps, \n",
    "    drift_rate=1, \n",
    "    threshold=3,\n",
    "    accumulate_sigma=1\n",
    ")\n",
    "chemo.seed(seed_value)\n",
    "\n",
    "info = AccumulatorInfoGrid(\n",
    "    min_length=min_length, \n",
    "    max_steps=max_steps, \n",
    "    drift_rate=1, \n",
    "    threshold=3,\n",
    "    accumulate_sigma=1\n",
    ")\n",
    "info.seed(seed_value)\n",
    "\n",
    "# !\n",
    "rand_exp = experiment(\n",
    "    f\"rand\",\n",
    "    diff,\n",
    "    env,\n",
    "    num_steps=num_steps,\n",
    "    num_experiments=num_experiments,\n",
    "    dump=False,\n",
    "    split_state=True,\n",
    "    seed=seed_value\n",
    ")\n",
    "chemo_exp = experiment(\n",
    "    f\"chemo\",\n",
    "    chemo,\n",
    "    env,\n",
    "    num_steps=num_steps * cog_mult,\n",
    "    num_experiments=num_experiments,\n",
    "    dump=False,\n",
    "    split_state=True,\n",
    "    seed=seed_value\n",
    ")\n",
    "info_exp = experiment(\n",
    "    f\"info\",\n",
    "    info,\n",
    "    env,\n",
    "    num_steps=num_steps * cog_mult,\n",
    "    num_experiments=num_experiments,\n",
    "    dump=False,\n",
    "    split_state=True,\n",
    "    seed=seed_value\n",
    ")"
   ]
  },
  {
   "source": [
    "### Deaths"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "results = [chemo_exp, info_exp, rand_exp]\n",
    "names = [\"Chemo\", \"Info\", \"Rando\"]\n",
    "colors = [\"blue\", \"green\", \"grey\"]\n",
    "\n",
    "# Score by eff\n",
    "scores = []\n",
    "for name, res, color in zip(names, results, colors):\n",
    "    scores.append(num_death(res))   \n",
    "\n",
    "# Tabulate\n",
    "m, sd = [], []\n",
    "for (name, s, c) in zip(names, scores, colors):\n",
    "    m.append(np.mean(s))\n",
    "    sd.append(np.std(s))\n",
    "\n",
    "# Plot means\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Deaths\")\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "source": [
    "### Total reward"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "results = [chemo_exp, info_exp, rand_exp]\n",
    "names = [\"Chemo\", \"Info\", \"Rando\"]\n",
    "colors = [\"blue\", \"green\", \"grey\"]\n",
    "\n",
    "# Score by eff\n",
    "scores = []\n",
    "for name, res, color in zip(names, results, colors):\n",
    "    r = total_reward(res)\n",
    "    scores.append(r)   \n",
    "\n",
    "# Tabulate\n",
    "m, sd = [], []\n",
    "for (name, s, c) in zip(names, scores, colors):\n",
    "    m.append(np.mean(s))\n",
    "    sd.append(np.std(s))\n",
    "\n",
    "# Plot means\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "plt.bar(names, m, yerr=sd, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Total reward\")\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "\n",
    "# Dists\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "for (name, s, c) in zip(names, scores, colors):\n",
    "    plt.hist(s, label=name, color=c, alpha=0.5, bins=np.linspace(0, np.max(scores), 50))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    sns.despine()"
   ]
  },
  {
   "source": [
    "#### Question 3.2\n",
    "Was your answer to 3.1 correct? If it was not, explain what you think you got wrong. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain your old intuition, and if it has changed, you new one."
   ]
  },
  {
   "source": [
    "#### Question 3.3\n",
    "If we were to vary _p scent_ from a small value, like the value of 0.1 we used to answer Q2.1, to a large value (of say 1), it would make sense that there is a crossing over point. That up until that point chemo-taxis will find more total reward, and then after it info-taxis will find more reward.\n",
    "\n",
    "What is the exact value of _p scent_ where info-taxis will dominate _total reward_ (on average). \n",
    "\n",
    "It might seem like there is no way to know this, or you need to guess. Neither are true. There is a single value, and you have all the information you need to reason it out.\n",
    "\n",
    "Note: _p scent_ is bound between (0, 1); also assume that _p scent_ is the only thing which is changed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain your reasoning."
   ]
  },
  {
   "source": [
    "#### Question 3.4\n",
    "Is it better to follow your nose (aka do chemo-taxis) or it is better to do info-taxis--if you had to choose only one of them? \n",
    "\n",
    "Consider the results for Sections 2 and 3 as a whole. Assume (wrongly) these simple tasks and models are a good standing for the natural world as a whole."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain yourself."
   ]
  },
  {
   "source": [
    "#### Question 3.5\n",
    "Of course there is no reason an intelligent animal would need to use only info-taxis or only chemo-taxis. Describe below a algorithm, or scheme, to unify these two approaches. \n",
    "\n",
    "_Be as detailed as you can be._"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain yourself."
   ]
  },
  {
   "source": [
    "#### Question 3.6\n",
    "\n",
    "Two recurring themes in these labs have been:\n",
    "- Many \"intelligent\" algorithms come with cost\n",
    "- Inductive bias will always fail; there is always a counterexample.\n",
    "\n",
    "On the basis of these themes, create a counterexample for the scheme you created in Q1.4. Under what conditions will your new idea probably fail to do better than either approach working independently? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here as a comment. Explain yourself."
   ]
  }
 ]
}