{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5c0fa7a4f8f1487a2aac67eb43e7b2e553808a81f9be50af9e1ab194481cfe22"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Introduction to _explorationlib_.\n",
    "\n",
    "This section has two goals. First to get you familiar with the python library used throughout to simulate and explore exploration. Second, is to get familiar with running that code online using Google's colaboratory.\n",
    "\n",
    "\n",
    "Google colab is a simple free way to run python code. See the _python_ chapter for more on it. Most of the chapters and assignments in this book have a button to open in colab. This notebook is a simple compact test for all the others. A quick way to make sure the rest should work. \n",
    "\n",
    "This section has two assignments."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Assignment 1\n",
    "\n",
    "Use the button to open this assignment in a colab. Once it is open, if it is open, run all the cells. Read each cell, then run it, that is. This simple test of the colab is also a good but basic introduction to _explorationlib_, which is the basis for all the experiments and assignments you will see.\n",
    "\n",
    "If there are no errors, celebrate and consider _this_ assignment complete. \n",
    "\n",
    "_Note:_ I assume that you, reader, are familiar with python programming already. If you are not, see the _Introduction to python_ assignment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Install _explorationlib_\n",
    "Colab's come with many of the libraries we will need. It does not come with _explorationlib_. It's a module we will be using, and was written to support this book. Let's Install it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/parenthetical-e/explorationlib\n",
    "!pip install celluloid # for the gifs"
   ]
  },
  {
   "source": [
    "### Import some modules\n",
    "From the standard library"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "import sys"
   ]
  },
  {
   "source": [
    "that are common to scientific programming in python"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "Import a bunch of functions from _explorationlib_. If our install using _pip_ above worked out, this next cell should run without error."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the explorers we will play with are called\n",
    "# \"agents\"; a bit of computer science jargon\n",
    "from explorationlib import agent\n",
    "\n",
    "# The environments we will simulate live in a \"gym\"\n",
    "from explorationlib import local_gym as gym\n",
    "\n",
    "# Computational experiments are run with 'experiment'\n",
    "from explorationlib.run import experiment\n",
    "\n",
    "# Here are some tools to select, save, and load\n",
    "# data from computational experiments\n",
    "from explorationlib.util import select_exp\n",
    "from explorationlib.util import load\n",
    "from explorationlib.util import save\n",
    "\n",
    "# A bunch of tools for plotting and for\n",
    "# movie making\n",
    "from explorationlib.plot import plot_position2d\n",
    "from explorationlib.plot import plot_length_hist\n",
    "from explorationlib.plot import plot_length\n",
    "from explorationlib.plot import plot_targets2d\n",
    "from explorationlib.plot import render_2d\n",
    "from explorationlib.plot import show_gif\n",
    "\n",
    "# A couple metrics for scoring how well, or poorly,\n",
    "# an exploration experiment went.\n",
    "from explorationlib.score import search_efficiency\n",
    "from explorationlib.score import average_reward"
   ]
  },
  {
   "source": [
    "### Configure plots \n",
    "to be be nicer looking. We don't _have_ to do this, but _why not_?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"font.size\"] = \"16\""
   ]
  },
  {
   "source": [
    "### Better autocomplete and development\n",
    "In our notebooks. Again, optional. If this errors out, and it might, skip it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "### Create \"data/\"\n",
    "Make a folder to keep experimental data in. We will use it for all our examples.\n",
    "\n",
    "**WARNING** When running in a colab, anything you save to \"data/\" will be lost as soon as you shutdown the colab. This is ok for now. We will cover ways to save your data permanently later on."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")"
   ]
  },
  {
   "source": [
    "### Run a simple experiment using _explorationlib_\n",
    "1. Instantiate a random walker, in a small 2d box environment, with walls and a lot of targets to find when exploring. Each target should have a value of '1'.\n",
    "2. Run an experiment, for 200 steps. \n",
    "3. Plot the env, target, the agents path in the experiment. \n",
    "4. Make a movie of experiment.\n",
    "5. Score the agent, and reward (targets), and its efficiency."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Instantiate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "exp_name = \"data/explorationlib_a1.pkl\"   # all experiments need names\n",
    "num_experiments = 1             # we only want to run one experiment \n",
    "num_steps = 200                 # how many exploration steps in space?\n",
    "\n",
    "scale = 2             # The noise scale; the diffusion constant\n",
    "detection_radius = 1  # How far can the agent see?\n",
    "boundary = (10, 10)   # a 2d world, 10 by 10\n",
    "mode = \"stopping\"     # stop when we hit a wall\n",
    "num_targets = 100     # how many thingss to \"eat\"?\n",
    "\n",
    "# Setup targets. Targets are an abstraction for the\n",
    "# thing we are exploring to find. For now, all targets\n",
    "# are just the number 1 placed randomly about.\n",
    "targets = gym.uniform_targets(num_targets, boundary)\n",
    "values = gym.constant_values(targets, 1)\n",
    "\n",
    "# Setup agent and env\n",
    "env = gym.Bounded(boundary=boundary, mode=mode)\n",
    "env.add_targets(targets, values)\n",
    "brownian = agent.Diffusion2d(scale=scale)"
   ]
  },
  {
   "source": [
    "#### Run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Cleanup old versions\n",
    "for path in glob.glob(f\"{exp_name}\"):\n",
    "    os.remove(path)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run!\n",
    "experiment(exp_name, brownian, env, num_steps=num_steps, num_experiments=num_experiments)\n",
    "exp_data = load(exp_name)"
   ]
  },
  {
   "source": [
    "#### Plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 2d env, and the targets (black dots)\n",
    "plot_targets2d(env, boundary=boundary, title=\"Simple box\", figsize=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the positions the agent took during its\n",
    "# random walk, and the targets (this time in red)\n",
    "#\n",
    "# Note: there are quite a few parameters you can play\n",
    "# with to change the size of the plot, colors, and so on.\n",
    "# See `explorationlib.plot` for all the options\n",
    "\n",
    "# Agent\n",
    "ax = None\n",
    "ax = plot_position2d(\n",
    "    exp_data,\n",
    "    boundary=boundary,\n",
    "    label=\"Brownian\",\n",
    "    color=\"black\",\n",
    "    alpha=1,\n",
    "    ax=ax,\n",
    ")\n",
    "# Targets\n",
    "ax = plot_targets2d(\n",
    "    env,\n",
    "    boundary=boundary,\n",
    "    color=\"red\",\n",
    "    alpha=1,\n",
    "    label=\"Targets\",\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "source": [
    "#### Score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_reward(exp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_efficiency(exp_data)"
   ]
  },
  {
   "source": [
    "_Direction_: Go back to the top of this section, and run it again. Each time you do you should generate a new exploration. You'll get different rewards and efficiency each time as well.\n",
    "\n",
    "_Question_: How much variation do you see from run to run? More to the point, if this was how you _had_ to explore the world, how well do you think you'd do? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Assignment 2\n",
    "### Science!\n",
    "Let's run our first real experiment. Let's assume that the walker from Assignment 1 has the optimal scale of noise to search its 10 by 10 box, with walls. (This is not tru but put that aside). Now, what if the \"world\" (its box) suddenly got ten times bigger, but the number of targets stayed the same.... \n",
    "\n",
    "The goal of this experiment is to find out, with your acting as an oracle. Can you help the walker discover a new noise scale that improves, or returns, the search efficient to its previous value?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First rerun the experiment with many more repeats, \n",
    "# so we get a stable estimate of the baseline value\n",
    "\n",
    "# Parameters\n",
    "exp_name = \"data/explorationlib_a2_10.pkl\"  \n",
    "scale=2                           # The noise scale; the diffusion constant\n",
    "num_experiments = 200             # 200 repeats!\n",
    "num_steps = 200                   # how many exploration steps in space?\n",
    "\n",
    "detection_radius = 1  # How far can the agent see?\n",
    "boundary = (10, 10)   # a 2d world, 10 by 10\n",
    "mode = \"stopping\"     # stop when we hit a wall\n",
    "num_targets = 100     # how many thingss to \"eat\"?\n",
    "\n",
    "# Setup targets. Targets are an abstraction for the\n",
    "# thing we are exploring to find. For now, all targets\n",
    "# are just the number 1 placed randomly about.\n",
    "targets = gym.uniform_targets(num_targets, boundary)\n",
    "values = gym.constant_values(targets, 1)\n",
    "\n",
    "# Setup agent and env\n",
    "env = gym.Bounded(boundary=boundary, mode=mode)\n",
    "env.add_targets(targets, values)\n",
    "brownian = agent.Diffusion2d(scale=scale)\n",
    "\n",
    "# Cleanup old versions\n",
    "for path in glob.glob(f\"{exp_name}\"):\n",
    "    os.remove(path)\n",
    "\n",
    "# Run!\n",
    "experiment(exp_name, brownian, env, num_steps=num_steps, num_experiments=num_experiments)\n",
    "exp_data = load(exp_name)\n",
    "\n",
    "# Score\n",
    "scores = search_efficiency(exp_data)\n",
    "print(f\">>> Mean {np.mean(scores)}, SD: {np.std(scores)}\")"
   ]
  },
  {
   "source": [
    "Now increase the `boundary` to be a (100, 100) box, and rerun the experiment above. _Note_: You can just copy the code, BUT make sure to choose a new `exp_name` as well.\n",
    "\n",
    "_Question_: Is a scale of 2 still optimal? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here."
   ]
  },
  {
   "source": [
    "Once you rerun with the big boundary, you will have an estimate for how the search efficiency has dropped. Now, rerun the experiment but this time experiment with different values of `scale`. \n",
    "\n",
    "_Question_: how much can you improve the mean score? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here."
   ]
  }
 ]
}